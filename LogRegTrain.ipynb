{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hrita\\anaconda3\\envs\\dirac\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 159571\n",
      "# toxic: 16225\n",
      "# toxic: 0.9041555169799024\n",
      "# severe_toxic: 0.9900044494300343\n",
      "# obscene: 0.947051782592075\n",
      "# threat: 0.9970044682304429\n",
      "# insult: 0.9506363938309592\n",
      "# identity_hate: 0.9911951419744189\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv/train.csv')\n",
    "total = df.shape[0]\n",
    "print('rows:', df.shape[0])\n",
    "# toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
    "print('# toxic:', df[(df['toxic'] == 1) | (df['severe_toxic'] == 1) | (df['obscene'] == 1) | (df['threat'] == 1) | (df['insult'] == 1) | (df['identity_hate'] == 1)].shape[0])\n",
    "\n",
    "print('# toxic:', 1-df[(df['toxic'] == 1)].shape[0]/total)\n",
    "print('# severe_toxic:', 1-df[(df['severe_toxic'] == 1)].shape[0]/total)\n",
    "print('# obscene:', 1-df[(df['obscene'] == 1)].shape[0]/total)\n",
    "print('# threat:', 1-df[(df['threat'] == 1)].shape[0]/total)\n",
    "print('# insult:', 1-df[(df['insult'] == 1)].shape[0]/total)\n",
    "print('# identity_hate:', 1-df[(df['identity_hate'] == 1)].shape[0]/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32450\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "resampling - undersampling\n",
    "'''\n",
    "\n",
    "# Count the number of labels per row (you might already have this)\n",
    "df['label_count'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
    "\n",
    "# Separate the minority and majority instances\n",
    "minority_df = df[df['label_count'] > 0]     # s = 16k\n",
    "majority_df = df[df['label_count'] == 0]\n",
    "\n",
    "# Under-sample the majority dataframe\n",
    "sampled_majority_df = majority_df.sample(n=len(minority_df))\n",
    "\n",
    "# Combine back the minority and downsampled majority instances\n",
    "balanced_df = pd.concat([minority_df, sampled_majority_df])\n",
    "\n",
    "# Now balanced_df is the under-sampled DataFrame\n",
    "df = balanced_df\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 32450\n",
      "# toxicity: 16225\n",
      "# toxic: 0.5286902927580894\n",
      "# severe_toxic: 0.9508474576271186\n",
      "# obscene: 0.7396302003081664\n",
      "# threat: 0.9852696456086286\n",
      "# insult: 0.7572573189522342\n",
      "# identity_hate: 0.9567026194144839\n"
     ]
    }
   ],
   "source": [
    "total = df.shape[0]\n",
    "print('rows:', df.shape[0])\n",
    "# toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
    "print('# toxicity:', df[(df['toxic'] == 1) | (df['severe_toxic'] == 1) | (df['obscene'] == 1) | (df['threat'] == 1) | (df['insult'] == 1) | (df['identity_hate'] == 1)].shape[0])\n",
    "\n",
    "print('# toxic:', 1-df[(df['toxic'] == 1)].shape[0]/total)\n",
    "print('# severe_toxic:', 1-df[(df['severe_toxic'] == 1)].shape[0]/total)\n",
    "print('# obscene:', 1-df[(df['obscene'] == 1)].shape[0]/total)\n",
    "print('# threat:', 1-df[(df['threat'] == 1)].shape[0]/total)\n",
    "print('# insult:', 1-df[(df['insult'] == 1)].shape[0]/total)\n",
    "print('# identity_hate:', 1-df[(df['identity_hate'] == 1)].shape[0]/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "cocksucker before you piss around on my work\n",
      "['cocksucker', 'before', 'you', 'piss', 'around', 'on', 'my', 'work']\n",
      "['cocksucker', 'piss', 'around', 'work']\n",
      "['cocksucker', 'piss', 'around', 'work']\n",
      "cocksucker piss around work\n",
      "  (0, 70116)\t0.36841989661122454\n",
      "  (0, 7999)\t0.4185522667627553\n",
      "  (0, 48639)\t0.5495493060800604\n",
      "  (0, 15327)\t0.6221545949003817\n",
      "  (1, 68179)\t0.13181942649756834\n",
      "  (1, 44648)\t0.2143077426641946\n",
      "  (1, 34730)\t0.11974909565530292\n",
      "  (1, 10210)\t0.15737065292629002\n",
      "  (1, 15029)\t0.1731964399550588\n",
      "  (1, 57549)\t0.26720643074482986\n",
      "  (1, 8313)\t0.1263563402492379\n",
      "  (1, 44444)\t0.2777365316772076\n",
      "  (1, 19537)\t0.2154621738029848\n",
      "  (1, 7343)\t0.24173387879126715\n",
      "  (1, 4859)\t0.2597352052342374\n",
      "  (1, 51309)\t0.11509816620524554\n",
      "  (1, 8322)\t0.21214228689383513\n",
      "  (1, 45864)\t0.08340080268346349\n",
      "  (1, 27117)\t0.18940599224571808\n",
      "  (1, 51004)\t0.24920510430185966\n",
      "  (1, 55958)\t0.23346350024595497\n",
      "  (1, 19533)\t0.2019607874960612\n",
      "  (1, 28120)\t0.10136562817258436\n",
      "  (1, 61281)\t0.2777365316772076\n",
      "  (1, 70251)\t0.315248049860063\n",
      "  :\t:\n",
      "  (32449, 22266)\t0.12693415572070216\n",
      "  (32449, 64541)\t0.11821691980242556\n",
      "  (32449, 48715)\t0.11454831653960498\n",
      "  (32449, 35297)\t0.15635399676210324\n",
      "  (32449, 38920)\t0.12633159646329903\n",
      "  (32449, 25353)\t0.1075554633297663\n",
      "  (32449, 24583)\t0.15395884365760784\n",
      "  (32449, 48842)\t0.08370091160619506\n",
      "  (32449, 37956)\t0.11071883974281811\n",
      "  (32449, 58584)\t0.09780913910997899\n",
      "  (32449, 8096)\t0.1406067714743207\n",
      "  (32449, 53283)\t0.13676708025827963\n",
      "  (32449, 6460)\t0.0906585217496323\n",
      "  (32449, 38241)\t0.07523652131138804\n",
      "  (32449, 64550)\t0.11669078883047677\n",
      "  (32449, 69287)\t0.0773851331922073\n",
      "  (32449, 53907)\t0.10261121788546097\n",
      "  (32449, 28233)\t0.11837162482493135\n",
      "  (32449, 27567)\t0.08548551664125523\n",
      "  (32449, 32769)\t0.08418545981155677\n",
      "  (32449, 70840)\t0.12832185757244532\n",
      "  (32449, 62944)\t0.0864669043085216\n",
      "  (32449, 38832)\t0.10188983009633493\n",
      "  (32449, 21014)\t0.07525904259768251\n",
      "  (32449, 61286)\t0.08172662940649975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6                           cocksucker piss around work\n",
       "12    hey talk exclusive group wp talibanswho good d...\n",
       "16         bye dont look come think comming back tosser\n",
       "42    gay antisemmitian archangel white tiger meow g...\n",
       "43                            fuck filthy mother as dry\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Basic Data Cleaning and Preprocessing\n",
    "NOTE:\n",
    "run time: 30 to 40 sec\n",
    "Tokenization: turn text into tokens\n",
    "Lemmatization: extracting a word's base form (ex: running -> run)\n",
    "'''\n",
    "\n",
    "\n",
    "# remove line breaks and special characters\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: re.sub(r'\\n', ' ', x))\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "print(df['comment_text'][6])\n",
    "\n",
    "# Convert to lowercase\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: x.lower())\n",
    "print(df['comment_text'][6])\n",
    "\n",
    "# Tokenization\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "print(df['comment_text'][6])\n",
    "\n",
    "# Removing Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "print(df['comment_text'][6])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "print(df['comment_text'][6])\n",
    "\n",
    "# Rejoin tokens into strings (for context for tfidf)\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x: ' '.join(x))\n",
    "print(df['comment_text'][6])\n",
    "\n",
    "# Create Vectorizer and transform data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorized_data = tfidf_vectorizer.fit_transform(df['comment_text'])\n",
    "print(tfidf_vectorized_data)\n",
    "\n",
    "# Example output\n",
    "df['comment_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Train and Val split\n",
    "'''\n",
    "\n",
    "# Prepare the target variable\n",
    "label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y = df[label_columns]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vectorized_data, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConvergenceWarning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[43mConvergenceWarning\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train a logistic regression model for each label\u001b[39;00m\n\u001b[0;32m      8\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalty\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1000\u001b[39m]\n\u001b[0;32m     13\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ConvergenceWarning' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "\n",
    "# Train a logistic regression model for each label\n",
    "param_grid = {\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "\n",
    "models = {}\n",
    "for column in y_train.columns:\n",
    "    # Initialize the grid search model\n",
    "    grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, n_jobs=-3)  \n",
    "    grid_search.fit(X_train, y_train[column])\n",
    "    models[column] = grid_search\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Make predictions and evaluate each model\n",
    "for label, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[label], y_pred)\n",
    "    print(f\"Accuracy for {label}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for toxic: 0.8749\n",
      "Best model params {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy for severe_toxic: 0.9536\n",
      "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy for obscene: 0.8992\n",
      "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy for threat: 0.9875\n",
      "Best model params {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy for insult: 0.8613\n",
      "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy for identity_hate: 0.9635\n",
      "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "for label, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[label], y_pred)\n",
    "    print(f\"Accuracy for {label}: {accuracy:.4f}\")\n",
    "    print(f'Best model params {model.best_params_}')\n",
    "    \n",
    "''' \n",
    "Accuracy for toxic: 0.8749\n",
    "Best model params {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
    "Accuracy for severe_toxic: 0.9536\n",
    "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "Accuracy for obscene: 0.8992\n",
    "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "Accuracy for threat: 0.9875\n",
    "Best model params {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "Accuracy for insult: 0.8613\n",
    "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "Accuracy for identity_hate: 0.9635\n",
    "Best model params {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
